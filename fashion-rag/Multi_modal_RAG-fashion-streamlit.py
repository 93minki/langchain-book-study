import os
import base64
import streamlit as st
from dotenv import load_dotenv
import chromadb
from chromadb.utils.embedding_functions import OpenCLIPEmbeddingFunction
from chromadb.utils.data_loaders import ImageLoader
from datasets import load_dataset
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

load_dotenv()

# ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì˜ ë””ë ‰í„°ë¦¬ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))


# ë°ì´í„°ì…‹ì„ ì„¤ì •í•˜ëŠ” í•¨ìˆ˜
def setup_dataset():
    # íŒ¨ì…˜ ê´€ë ¨ ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°
    dataset = load_dataset("detection-datasets/fashionpedia")
    # ë°ì´í„°ì…‹ì„ ì €ì¥í•  í´ë” ê²½ë¡œ ì„¤ì •
    dataset_folder = os.path.join(SCRIPT_DIR, "fashion_dataset")
    # í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
    os.makedirs(dataset_folder, exist_ok=True)
    return dataset, dataset_folder


# ë°ì´í„°ì…‹ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•˜ëŠ” í•¨ìˆ˜
def save_images(dataset, dataset_folder, num_images=1000):
    # ì£¼ì–´ì§„ ìˆ˜ì˜ ì´ë¯¸ì§€ë¥¼ ì €ì¥
    for i in range(num_images):
        image = dataset["train"][i]["image"]
        image.save(os.path.join(dataset_folder, f"image_{i+1}.png"))
    print(f"{num_images}ê°œì˜ ì´ë¯¸ì§€ë¥¼ {dataset_folder}ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")


# Chroma ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì„¤ì •í•˜ëŠ” í•¨ìˆ˜
def setup_chroma_db():
    # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ê²½ë¡œ ì„¤ì •
    vdb_path = os.path.join(SCRIPT_DIR, "img_vdb")
    # Chroma í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    chroma_client = chromadb.PersistentClient(path=vdb_path)
    # ì´ë¯¸ì§€ ë¡œë” ë° OpenCLIP ì„ë² ë”© í•¨ìˆ˜ ì„¤ì •
    image_loader = ImageLoader()
    clip = OpenCLIPEmbeddingFunction()
    # ì´ë¯¸ì§€ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ë˜ëŠ” ê°€ì ¸ì˜¤ê¸°
    image_vdb = chroma_client.get_or_create_collection(
        name="image", embedding_function=clip, data_loader=image_loader
    )
    return image_vdb


# ê¸°ì¡´ì— ì¡´ì¬í•˜ëŠ” ì´ë¯¸ì§€ IDsë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
def get_existing_ids(image_vdb, dataset_folder):
    existing_ids = set()
    try:
        # dataset_folder ë‚´ì˜ ì´ë¯¸ì§€ íŒŒì¼ ìˆ˜ ê³„ì‚°
        num_images = len([name for name in os.listdir(dataset_folder)])
        print(f"ë°ì´í„° í´ë” ì „ì²´ ì´ë¯¸ì§€ìˆ˜: {num_images}")
        records = image_vdb.query(
            query_texts=[""], n_results=num_images, include=["ids"]
        )
        for record in records["ids"]:
            existing_ids.update(record)
            print(f"{len(record)} ì¡´ì¬ IDs")
    except Exception as e:
        print(f"{len(record)}ê°œì˜ ê¸°ì¡´ IDsê°€ ìˆìŠµë‹ˆë‹¤.")
    return existing_ids


# ì´ë¯¸ì§€ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì¶”ê°€í•˜ëŠ” í•¨ìˆ˜
def add_images_to_db(image_vdb, dataset_folder):
    existing_ids = get_existing_ids(image_vdb, dataset_folder)
    ids = []
    uris = []
    # í´ë”ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì½ì–´ì™€ì„œ ë°ì´í„°ë² ì´ìŠ¤ì— ì¶”ê°€
    for i, filename in enumerate(sorted(os.listdir(dataset_folder))):
        if filename.endswith(".png"):
            img_id = str(i)
            if img_id not in existing_ids:
                file_path = os.path.join(dataset_folder, filename)
                ids.append(img_id)
                uris.append(file_path)

    if ids:
        image_vdb.add(ids=ids, uris=uris)
        print("ìƒˆë¡œìš´ ì´ë¯¸ì§€ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.")
    else:
        print("ì¶”ê°€í•  ìƒˆë¡œìš´ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")


# ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•˜ëŠ” í•¨ìˆ˜
def query_db(image_vdb, query, results=2):
    # ì£¼ì–´ì§„ ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•˜ê³ , ìƒìœ„ ê²°ê³¼ ë°˜í™˜
    return image_vdb.query(
        query_texts=[query],
        n_results=results,
        include=["uris", "distances"],
    )


# í…ìŠ¤íŠ¸ë¥¼ ì§€ì •ëœ ì–¸ì–´ë¡œ ë²ˆì—­í•˜ëŠ” í•¨ìˆ˜
def translate(text, target_lang):
    # OpenAIì˜ ChatGPT ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë²ˆì—­
    translate_model = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
    # ë²ˆì—­ì— ì‚¬ìš©í•  í”„ë¡¬í”„íŠ¸ ì„¤ì •
    translation_prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                f"You are a translator. Translate the following text to {target_lang}",
            ),
            ("user", f"{text}"),
        ]
    )
    # ë²ˆì—­ ì²´ì¸ ì„¤ì •
    translate_chain = translation_prompt | translate_model | StrOutputParser()
    # ë²ˆì—­ ê²°ê³¼ ë°˜í™˜
    return translate_chain.invoke({"text": text})


def setup_vision_chain():
    # GPT-4 ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì‹œê°ì  ì •ë³´ë¥¼ ì²˜ë¦¬ gpt-4o ro gpt-4o-mini ëª¨ë¸ ì„ íƒ
    gpt4 = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    parser = StrOutputParser()
    image_prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                "You are a helpful fashion and styling assistant. Answer the user's question using the given image context with direct reference to parts of the images provided. Maintain a more conversational tone, don't make too many lists. Use markdown formatting for highlights, emphasis, and structure.",
            ),
            (
                "user",
                [
                    {
                        "type": "text",
                        "text": "What are some ideas for styling {user_query}",
                    },
                    {
                        "type": "image_url",
                        "image_url": "data:image/jpeg;base64,{image_data_1}",
                    },
                    {
                        "type": "image_url",
                        "image_url": "data:image/jpeg;base64,{image_data_2}",
                    },
                ],
            ),
        ]
    )
    return image_prompt | gpt4 | parser


def format_prompt_inputs(data, user_query):
    inputs = {}

    # ì‚¬ìš©ì ì§ˆë¬¸ì„ ë”•ì…”ë„ˆë¦¬ì— ì¶”ê°€
    inputs["user_query"] = user_query

    # 'uris' ë¦¬ìŠ¤íŠ¸ì—ì„œ ì²« ë‘ ì´ë¯¸ì§€ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
    image_path_1 = data["uris"][0][0]
    image_path_2 = data["uris"][0][1]

    # ì²« ë²ˆì§¸ ì´ë¯¸ì§€ ì¸ì½”ë”©
    with open(image_path_1, "rb") as image_file:
        image_data_1 = image_file.read()
    inputs["image_data_1"] = base64.b64encode(image_data_1).decode("utf-8")

    # ë‘ ë²ˆì§¸ ì´ë¯¸ì§€ ì¸ì½”ë”©
    with open(image_path_2, "rb") as image_file:
        image_data_2 = image_file.read()
    inputs["image_data_2"] = base64.b64encode(image_data_2).decode("utf-8")
    return inputs


# ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜
def load_image_as_base64(image_path):
    with open(image_path, "rb") as img_file:
        return base64.b64encode(img_file.read()).decode("utf-8")


# Streamlit ì•±ì„ ì‹¤í–‰í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜
def main():
    st.set_page_config(page_title="FashionRAG", page_icon="ğŸ‘ ", layout="wide")
    st.title("FashionRAG: íŒ¨ì…˜ ë° ìŠ¤íƒ€ì¼ë§ ì–´ì‹œìŠ¤í„´íŠ¸")
    # ë°ì´í„°ì…‹ í´ë” ë° ì´ë¯¸ì§€ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    dataset_folder = os.path.join(SCRIPT_DIR, "fashion_dataset")
    if not os.path.exists(dataset_folder) or not any(
        fname.endswith(".png") for fname in os.listdir(dataset_folder)
    ):
        with st.spinner("ë°ì´í„°ì…‹ ì„¤ì • ë° ì´ë¯¸ì§€ ì €ì¥ ì¤‘..."):
            dataset, dataset_folder = setup_dataset()
            save_images(dataset, dataset_folder)
        st.success("ë°ì´í„°ì…‹ ì„¤ì • ë° ì´ë¯¸ì§€ ì €ì¥ ì¤‘...")
    else:
        st.info("ë°ì´í„°ì…‹ì´ ì„¤ì •ë˜ê³  ì´ë¯¸ì§€ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ì—¬ë¶€ í™•ì¸
    vdb_path = os.path.join(SCRIPT_DIR, "img_vdb")
    if not os.path.exists(vdb_path) or not os.listdir(vdb_path):
        with st.spinner("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ë° ì´ë¯¸ì§€ ì¶”ê°€ ì¤‘..."):
            image_vdb = setup_chroma_db()
            add_images_to_db(image_vdb, dataset_folder)
        st.success("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ë° ì´ë¯¸ì§€ ì¶”ê°€ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        st.info(
            "ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ ì´ë¯¸ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •ì„ ê±´ë„ˆëœë‹ˆë‹¤."
        )
        image_vdb = setup_chroma_db()
    vision_chain = setup_vision_chain()
    st.header("ìŠ¤íƒ€ì¼ë§ ì¡°ì–¸ì„ ë°›ì•„ë³´ì„¸ìš”")
    query_ko = st.text_input("ìŠ¤íƒ€ì¼ë§ì— ëŒ€í•œ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")
    if query_ko:
        with st.spinner("ë²ˆì—­ ë° ì¿¼ë¦¬ ì§„í–‰ì¤‘..."):
            query_en = translate(query_ko, "English")
            results = query_db(image_vdb, query_en, results=2)
            prompt_input = format_prompt_inputs(results, query_en)
            response_en = vision_chain.invoke(prompt_input)
            response_ko = translate(response_en, "Korean")
        st.subheader("ê²€ìƒ‰ëœ ì´ë¯¸ì§€:")
        for idx, uri in enumerate(results["uris"][0]):
            img_base64 = load_image_as_base64(uri)
            img_data_url = f"data:image/png;base64,{img_base64}"
            st.image(img_data_url, caption=f"ID: {results['ids'][0][idx]}", width=300)
        st.subheader("FashionRAGì˜ ì‘ë‹µ:")
        st.markdown(response_ko)


if __name__ == "__main__":
    main()
